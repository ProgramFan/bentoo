#!/usr/bin/env python2.7
#

'''Analyser - Test project result analyser

Analyser provides command line interface to extract and display test result
data collected by Collector. It provided options to filter result, to choose
display table fields and to pivot resultant table. It provides a simple and
intuitive syntax.

To use the analyser, one invokes analyser.py with -m for matcher/filter, -f for
fields selection and -p for pivoting. For example, one can display how all
timers of algorithms scales w.r.t. number of nodes when using 1 threads per
process using the following command line:
    ./analyser.py result.sqlite -m nthreads=1 -m timer_name~algs::Numerical*,
    algs::Copy* -f timer_name,nnodes,max,summed -p timer_name,nnodes

Analyser tries to provide a simple CLI interface of pandas for simple use
cases, namely tasks need to be done quick and often in command line. More
sphosticated analysis need to be done directly in python using pandas etc.
'''


import os
import sys
import argparse
import re
import fnmatch
import sqlite3
import pandas

sqlite_types = {
    None: "NULL",
    int: "INTEGER",
    long: "INTEGER",
    float: "REAL",
    str: "TEXT",
    unicode: "TEXT",
    buffer: "BLOB"
}

sqlite_glob_ops = {
    "fnmatchcase": "GLOB",
    "fnmatch": "GLOB",
    "regex": "REGEXP"
}


def build_sql_where(column_types, spec, syntax="fnmatch"):
    if not spec:
        return ""

    assert syntax in sqlite_glob_ops

    def quote(name, value):
        assert name in column_types
        sqlite_type = sqlite_types[column_types[name]]
        if sqlite_type == "TEXT":
            return "'{0}'".format(value)
        elif sqlite_type == "BLOB":
            return "x'{0}'".format(value)
        elif sqlite_type == "NULL":
            return ""
        else:
            return value

    sql_start = "WHERE "
    sql_segs = []
    for item in spec:
        m = re.match(r'^(\w+)\s*([=~])\s*(.*)$', item)
        assert m is not None
        name, op, value = m.groups()
        if name not in column_types:
            continue
        if "," in value:
            value = [x.strip() for x in value.split(",")]
        else:
            value = value.strip()
        if op == "=":
            if isinstance(value, list):
                value = map(lambda x: quote(name, x), value)
                sql_seg = "{0} IN ({1})".format(name, ", ".join(value))
            else:
                value = quote(name, value)
                sql_seg = "{0} == {1}".format(name, value)
        else:
            assert sqlite_types[column_types[name]] == "TEXT"
            glob_op = sqlite_glob_ops[syntax]
            if isinstance(value, list):
                quoted = ["{0} {1} '{2}'".format(name, glob_op, x)
                          for x in value]
                sql_seg = "(" + " OR ".join(quoted) + ")"
            else:
                sql_seg = "{0} {1} '{2}'".format(name, glob_op, value)
        sql_segs.append(sql_seg)
    return sql_start + " AND ".join(sql_segs)


def build_sql_select(column_types, fields):
    if not fields:
        return "*"
    fields_new = []
    for f in fields:
        fields_new.extend(x.strip() for x in f.split(","))
    for f in fields_new:
        assert f in column_types
    return ", ".join(fields_new)


class SqliteReader:
    def open(self, fn):
        conn = sqlite3.connect(fn)
        self.conn = conn
        # Determine the columns and column types, which is needed by
        # read_frame_select to determine proper quotation.
        cur = self.conn.cursor()
        cur.execute("SELECT * FROM result ORDER BY ROWID ASC LIMIT 1")
        row = cur.fetchone()
        column_names = [x[0] for x in cur.description]
        column_types = [type(x) for x in row]
        self.columns = column_names
        self.column_types = dict(zip(column_names, column_types))
        # Register regex function
        self.conn.create_function("regexp", 2,
                                  lambda x, y: 1 if re.match(x, y) else 0)

    def read_frame(self):
        return pandas.io.sql.read_sql("SELECT * FROM result", self.conn)

    def read_frame_select(self, matches, syntax, fields):
        sql_selector = build_sql_select(self.column_types, fields)
        sql = "SELECT {0} FROM result ".format(sql_selector)
        sql += build_sql_where(self.column_types, matches, syntax)
        print sql
        return pandas.io.sql.read_sql(sql, self.conn)

    def close(self):
        self.conn.close()


def main():
    parser = argparse.ArgumentParser(
        description=__doc__, formatter_class=argparse.RawTextHelpFormatter)
    parser.add_argument("data_file",
                        help="Data file generated by Collector")
    parser.add_argument("-f", "--field", action='append', default=[],
                        help="Field to display, value or list of values")
    parser.add_argument("-m", "--match", "--filter",
                        action='append', default=[],
                        help="Data record matcher, name[~=]value")
    parser.add_argument("--glob-syntax", "--matcher-syntax",
                        choices=["fnmatch", "fnmatchcase", "regex"],
                        default="fnmatch",
                        help="Syntax for glob matcher (default: fnmatch)")
    parser.add_argument("-p", "--pivot",
                        help="Pivoting fields, 2 or 3 element list")
    parser.add_argument("-s", "--save",
                        help="Save result to a CSV file")

    args = parser.parse_args()

    reader = SqliteReader()
    reader.open(args.data_file)
    value = reader.read_frame_select(args.match, args.glob_syntax, args.field)
    if args.pivot:
        fields_new = [x.strip() for x in args.pivot.split(",")]
        value = value.pivot(*fields_new)
    print value.to_string()
    if args.save:
        value.to_csv(args.save, index=False)


if __name__ == "__main__":
    main()
