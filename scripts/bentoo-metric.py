#!/usr/bin/env python2.7
#
'''Metric - Performance Metric Calculator

Metric uses predefined formulee to calculate certain performance metrics from a
set of performance counter values. It currently supports the likwid style of
performance group.

To use Metric, feed it a database file generated by 'bentoo-collector', it will
calculate automatically derived formulee defined in likwid perfgroup format.
Note that only raw performance counters shall be stored in the database.
'''

import os
import re
import argparse
import sqlite3


#
# Likwid Helpers
#

class BlockReader(object):

    def __init__(self, start, end, use_regex=False):
        if use_regex:
            self.start_ = re.compile(start)

            def match_start(x):
                return self.start_.match(x)
            self.match_start = match_start

            self.end = re.compile(end)

            def match_end(x):
                return self.end_.match(x)
            self.match_end = match_end
        else:
            def match_start(x):
                return x == self.start_

            def match_end(x):
                return x == self.end_

            self.start_ = start
            self.end_ = end
            self.match_start = match_start
            self.match_end = match_end

    def iterblocks(self, iterable):
        while True:
            try:
                block = []
                while not self.match_start(iterable.next()):
                    continue
                line = iterable.next()
                while not self.match_end(line):
                    block.append(line)
                    line = iterable.next()
                yield block
            except StopIteration:
                return

    def findblock(self, iterable):
        block = []
        while not self.match_start(iterable.next()):
            continue
        line = iterable.next()
        while not self.match_end(line):
            block.append(line)
            line = iterable.next()
        return block


class EventsetParser(object):

    def __init__(self):
        self.events = []
        self.counters = []

    def process(self, iterable):
        for line in iterable:
            counter, event = line.split()
            self.events.append(event)
            self.counters.append(counter)


class MetricsParser(object):

    def __init__(self):
        self.metrics = []

    def process(self, iterable):
        for line in iterable:
            if re.findall(r"\[.*\]", line):
                name, unit, formula = map(lambda x: x.strip(),
                                          re.match(r"^(.*?)\[(.*?)\](.*)$",
                                                   line).groups())
                self.metrics.append((name, unit, formula))
            else:
                name, formula = map(lambda x: x.strip(),
                                    re.match(r"^(.*?)(\S+)$", line).groups())
                self.metrics.append((name, "1", formula))


class LikwidMetrics(object):

    def __init__(self, group_file):
        with open(group_file) as groupfile:
            eventset_reader = BlockReader("EVENTSET\n", "\n")
            metrics_reader = BlockReader("METRICS\n", "\n")
            ep = EventsetParser()
            mp = MetricsParser()
            ep.process(eventset_reader.findblock(groupfile))
            mp.process(metrics_reader.findblock(groupfile))
            self.eventset = {"events": ep.events, "counters": ep.counters,
                             "pair": ["%s:%s" % x for x in zip(ep.events,
                                                               ep.counters)]}
            self.metrics = mp.metrics

    def event_count(self):
        return len(self.eventset["events"])

    def event_name(self, event_id):
        return self.eventset["events"][event_id]

    def counter_name(self, event_id):
        return self.eventset["counters"][event_id]

    def event_counter_pair(self, event_id):
        return self.eventset["pair"][event_id]

    def metric_count(self):
        return len(self.metrics)

    def metric_name(self, metric_id):
        return self.metrics[metric_id][0]

    def metric_unit(self, metric_id):
        return self.metrics[metric_id][1]

    def calc_metric(self, metric_id, eventvals):
        formula = str(self.metrics[metric_id][2])
        for k, v in eventvals.iteritems():
            formula = formula.replace(k, str(v))
        return eval(formula)


#
# Metric Calculator
#

SQLITE_TYPE = {
    None: "NULL",
    int: "INTEGER",
    long: "INTEGER",
    float: "REAL",
    str: "TEXT",
    unicode: "TEXT",
    buffer: "BLOB"
}


def stringify(content):
    return re.sub("\s", "_", content)


def is_event(name):
    matcher = re.compile(r"\w+:\w+")
    return matcher.match(name)


def calc_likwid_metric(group_file, data_file, output_file, aggregate="no"):
    assert(aggregate in ("no", "thread", "proc_thread"))

    conn0 = sqlite3.connect(data_file)
    conn0.row_factory = sqlite3.Row

    # Discover the structure of input database
    sql = "select * from result limit 1"
    r0 = conn0.execute(sql).fetchone()
    input_keys = r0.keys()
    input_types = [type(x) for x in r0]

    # Build select pipeline
    def is_value_key(k):
        if k in ("RDTSC", "CallCount"):
            return True
        if is_event(k):
            # match the "CPU_CYC_HALT:FIXC0" event counter
            return True
        return False
    select = []
    group_by = []
    if aggregate == "no":
        select = ["\"%s\"" % k for k in input_keys]
        group_by = [k for k in input_keys if not is_value_key(k)]
    elif aggregate == "thread":
        for k in input_keys:
            if k == "ThreadId":
                select.append("COUNT(ThreadId) AS ThreadCount")
            elif k == "RDTSC":
                select.append("SUM(RDTSC) AS SumRDTSC")
                select.append("MAX(RDTSC) AS MaxRDTSC")
            elif k == "CallCount":
                select.append("SUM(CallCount) AS SumCallCount")
            elif is_event(k):
                select.append("SUM(\"{0}\") AS \"{0}\"".format(k))
            else:
                select.append(k)
                # group by all remaining non value keys
                group_by.append("\"%s\"" % k)
    else:
        for k in input_keys:
            if k == "ProcId":
                select.append("COUNT(ProcId) AS ProcCount")
            elif k == "ThreadId":
                select.append("COUNT(ThreadId) AS ThreadCount")
            elif k == "RDTSC":
                select.append("SUM(RDTSC) AS SumRDTSC")
                select.append("MAX(RDTSC) AS MaxRDTSC")
            elif k == "CallCount":
                select.append("SUM(CallCount) AS SumCallCount")
            elif is_event(k):
                select.append("SUM(\"{0}\") AS \"{0}\"".format(k))
            else:
                select.append(k)
                # group by all remaining non value keys
                group_by.append("\"%s\"" % k)

    select = ", ".join(select)
    group_by = ", ".join(group_by)
    select_sql = "SELECT {0} FROM result WHERE {1} GROUP BY {2}".format(
        select, "TimerName != \"CPU_CYCLES\"", group_by)

    # Query CPU clock cycles stored in the database to calculate derived
    # metrics.
    sql = "select RDTSC from result where TimerName = \"CPU_CYCLES\" limit 1"
    cpu_cycles = conn0.execute(sql).fetchone()["RDTSC"]

    # create result sqlite database
    likwid = LikwidMetrics(group_file)
    c0 = conn0.cursor()
    c0.execute(select_sql)
    r0 = c0.fetchone()
    output_keys = [k for k in r0.keys() if not is_event(k)]
    output_types = [type(r0[k]) for k in output_keys]
    for i in xrange(likwid.metric_count()):
        output_keys.append(stringify(likwid.metric_name(i)))
        output_types.append(float)

    conn1 = sqlite3.connect(output_file)
    conn1.execute("DROP TABLE IF EXISTS result")
    type_pairs = zip(output_keys, output_types)
    sql = ["\"{0}\" {1}".format(k, SQLITE_TYPE[v]) for k, v in type_pairs]
    sql = "CREATE TABLE result (%s)" % ", ".join(sql)
    conn1.execute(sql)

    def compute_metrics(r0):
        event_values = dict()
        result = []
        for k, v in zip(r0.keys(), r0):
            if is_event(k):
                counter_name = k.split(":")[-1]
                event_values[counter_name] = v
            else:
                result.append(v)
        if aggregate != "no":
            event_values["time"] = r0["MaxRDTSC"]
        else:
            event_values["time"] = r0["RDTSC"]
        event_values["inverseClock"] = 1.0 / cpu_cycles
        for i in xrange(likwid.metric_count()):
            result.append(likwid.calc_metric(i, event_values))
        return result

    metrics = compute_metrics(r0)
    ph_sql = ", ".join(["?"] * len(metrics))
    insert_row_sql = "INSERT INTO result VALUES ({0})".format(ph_sql)
    conn1.execute(insert_row_sql, metrics)
    for r0 in c0.fetchall():
        metrics = compute_metrics(r0)
        ph_sql = ", ".join(["?"] * len(metrics))
        insert_row_sql = "INSERT INTO result VALUES ({0})".format(ph_sql)
        conn1.execute(insert_row_sql, metrics)

    conn1.commit()
    conn1.close()
    conn0.close()


def main():
    parser = argparse.ArgumentParser(
        description=__doc__,
        formatter_class=argparse.RawDescriptionHelpFormatter)
    parser.add_argument("group_file",
                        help="Likwid perfgroup definition")
    parser.add_argument("data_file",
                        help="Database containing raw event values")
    parser.add_argument("output_file",
                        help="Database to store calculated metrics")
    parser.add_argument("--aggregate", default="thread",
                        choices=["no", "thread", "proc_thread"],
                        help="Data aggregation (default: thread)")

    args = parser.parse_args()
    calc_likwid_metric(**vars(args))


if __name__ == "__main__":
    main()
