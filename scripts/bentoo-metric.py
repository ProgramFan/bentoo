#!/usr/bin/env python2.7
#
'''Metric - Performance Metric Calculator

Metric uses predefined formulee to calculate certain performance metrics from a
set of performance counter values. It currently supports the likwid style of
performance group.

To use Metric, feed it a database file generated by 'bentoo-collector', it will
calculate automatically derived formulee defined in likwid perfgroup format.
Note that only raw performance counters shall be stored in the database.
'''

#
# sample inputs:
#
# {
#    "trans_names": {
#       "CASXXX": "MBOXC1"
#    },
#    "metrics": {
#       "MFlop/s": "MBOXC1 * 64"
#    }
# }
#
# If one want to retain the order of metrics, use OrderedDict instead.
# Each metric is of type "float".
#

import os
import re
import argparse
import sqlite3


#
# Metric Calculator
#

SQLITE_TYPE = {
    type(None): "NULL",
    int: "INTEGER",
    long: "INTEGER",
    float: "REAL",
    str: "TEXT",
    unicode: "TEXT",
    buffer: "BLOB"
}


def column_split(columns):
    '''split 'columns' into (index_columns, data_columns)'''
    timer_column_index = columns.index("TimerName")
    return (columns[:timer_column_index+1], columns[timer_column_index+1:])


def eval_metric(formula, values):
    for k, v in values.iteritems():
        formula = formula.replace(str(k), str(v))
    try:
        result = eval(formula)
    except ValueError:
        result = 0.0
    return result


def calc_metric(raw_db, output_db, formula):
    conn0 = sqlite3.connect(raw_db)
    conn0.row_factory = sqlite3.Row

    # Discover the structure of input database
    sql = "select * from result limit 1"
    r0 = conn0.execute(sql).fetchone()
    input_columns = r0.keys()
    index_columns, data_columns = column_split(input_columns)

    output_columns = index_columns + formula["metrics"].keys()
    output_types = [type(x) for x in r0]
    output_types.extend(float for x in formula["metrics"])

    def quote(x):
        return "\"{}\"".format(x)

    select = map(quote, input_columns)
    select = ", ".join(select)
    order_by = map(quote, index_columns)
    order_by = ", ".join(order_by)
    select_sql = "SELECT {0} FROM result ORDER BY {1}".format(
        select, order_by)
    c0 = conn0.cursor()
    r0 = c0.execute(select_sql)
    r0 = c0.fetchone()

    conn1 = sqlite3.connect(output_db)
    conn1.execute("DROP TABLE IF EXISTS result")
    type_pairs = zip(output_columns, output_types)
    sql = ["\"{0}\" {1}".format(k, SQLITE_TYPE[v]) for k, v in type_pairs]
    sql = "CREATE TABLE result (%s)" % ", ".join(sql)
    conn1.execute(sql)

    def compute_metrics(r0):
        to_replace = dict(r0)
        for k, v in formula["trans_names"]:
            if k in r0:
                to_replace[v] = to_replace[k]
                del to_replace[k]
        result = [r0[k] for k in index_columns]
        for k, v in formula["metrics"].iteritems():
            value = eval_metric(v, to_replace)
            result.append(value)
        return result

    metrics = compute_metrics(r0)
    ph_sql = ", ".join(["?"] * len(metrics))
    insert_row_sql = "INSERT INTO result VALUES ({0})".format(ph_sql)
    conn1.execute(insert_row_sql, metrics)
    for r0 in c0.fetchall():
        metrics = compute_metrics(r0)
        ph_sql = ", ".join(["?"] * len(metrics))
        insert_row_sql = "INSERT INTO result VALUES ({0})".format(ph_sql)
        conn1.execute(insert_row_sql, metrics)

    conn1.commit()
    conn1.close()
    conn0.close()


def main():
    parser = argparse.ArgumentParser(
        description=__doc__,
        formatter_class=argparse.RawDescriptionHelpFormatter)
    parser.add_argument("raw_db",
                        help="Database containing raw event values")
    parser.add_argument("output_db",
                        help="Database to store calculated metrics")
    parser.add_argument("formula",
                        help="Formula to use")
    group = parser.add_mutually_exclusive_group(required=True)
    group.add_argument("--likwid-arch", default=None,
                       help="Likwid architecture name")
    group.add_argument("--likwid-group", default=None,
                       help="Likwid perfgroup name")
    group.add_argument("--likwid-group-file", default=None,
                       help="Likwid perfgroup file")
    group.add_argument("--user-defined-formula", default=None
                       help="Compute raw events instead of metrics")

    args = parser.parse_args()
    calc_likwid_metric(**vars(args))


if __name__ == "__main__":
    main()
